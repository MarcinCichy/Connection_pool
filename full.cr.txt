==================== 
FILE: server_package/config.py 

from configparser import ConfigParser


def load_config(filename='settings.ini', section=None):
    if section is None:
        raise ValueError("Section must be specified")

    parser = ConfigParser()
    parser.read(filename)

    if not parser.has_section(section):
        raise Exception(f'Section {section} not found in the {filename} file')

    return {param[0]: param[1] for param in parser.items(section)}


def db_config(filename='settings.ini'):
    return load_config(filename, 'postgresql')


def connection_pool_config(filename='settings.ini'):
    return load_config(filename, 'connection_pool')


def server_data(filename='settings.ini'):
    return load_config(filename, 'server_data')


def stress_test(filename='settings.ini'):
    return load_config(filename, 'stress_test')


def test_connection_usage(filename='settings.ini'):
    return load_config(filename, 'test_connection_usage') 

==================== 
FILE: server_package/conn_pool.py 

import threading
import time
from psycopg2 import connect as pg_connect
from connection_pool.server_package.config import db_config

class ConnectionPool:
    def __init__(self, minconn, maxconn, cleanup_interval):
        self.minconn = int(minconn)
        self.maxconn = int(maxconn)
        self.cleanup_interval = int(cleanup_interval)
        self.all_connections = []
        self.in_use_conn = 0
        self.threads_waiting = 0
        self.total_threads = 0
        self.lock = threading.Lock()
        self.semaphore = threading.BoundedSemaphore(self.maxconn)
        self.initialize_pool()
        self.start_cleanup_thread()

    def initialize_pool(self):
        with self.lock:
            for _ in range(self.minconn):
                self.all_connections.append(self.create_new_connection())
            print(f"Initialized connection pool with {self.minconn} connections.")

    def create_new_connection(self):
        params = db_config()
        conn = pg_connect(**params)
        print(f"[CREATE] New connection created: {conn}")
        return conn

    def acquire(self):
        print("[DEBUG] Attempting to acquire semaphore...")
        with self.lock:
            self.threads_waiting += 1
            self.total_threads += 1
        if not self.semaphore.acquire(timeout=10):
            with self.lock:
                self.threads_waiting -= 1
            raise Exception("Failed to acquire a connection: Timeout")

        with self.lock:
            self.threads_waiting -= 1
            if self.all_connections:
                conn = self.all_connections.pop()
                print(f"[ACQUIRE] Connection acquired from pool: {conn}")
            else:
                conn = self.create_new_connection()
                print(f"[ACQUIRE] New connection created and acquired: {conn}")
            self.in_use_conn += 1
            return conn

    def release(self, conn):
        with self.lock:
            if not conn:
                print("[RELEASE ERROR] No connection provided to release.")
                return
            if self.is_connection_closed(conn):
                print(f"[RELEASE ERROR] Connection is already closed and will not be released: {conn}")
                return

            self.in_use_conn -= 1
            if not self.is_connection_closed(conn):
                if len(self.all_connections) < self.maxconn:
                    self.all_connections.append(conn)
                    print(f"[RELEASE] Connection added back to pool: {conn}")
                else:
                    self.close_connection(conn)
                    print(f"[RELEASE] Connection closed as pool is full: {conn}")
            else:
                print(f"[RELEASE] Connection was already closed and not added to pool: {conn}")

            self.semaphore.release()

    def handle_connection_error(self, conn):
        print(f"[ERROR] Handling connection error for: {conn}")
        with self.lock:
            if conn and not self.is_connection_closed(conn):
                self.in_use_conn -= 1
                self.close_connection(conn)
                print(f"[ERROR] Connection closed due to error: {conn}")

            if len(self.all_connections) < self.maxconn:
                new_conn = self.create_new_connection()
                self.all_connections.append(new_conn)
                print(f"[ERROR] Replaced bad connection with a new one: {new_conn}")

            self.semaphore.release()

    def cleanup_pool(self):
        with self.lock:
            print(f"[CLEANUP] Starting cleanup. Available connections before cleanup: {len(self.all_connections)}")
            while len(self.all_connections) > self.minconn:
                conn = self.all_connections.pop()
                self.close_connection(conn)
            print(f"[CLEANUP] Cleanup finished. Available connections after cleanup: {len(self.all_connections)}")

    def close_connection(self, conn):
        try:
            if not self.is_connection_closed(conn):
                conn.close()
                print(f"[CLOSE CONNECTION] Connection closed: {conn}")
            else:
                print(f"[CLOSE CONNECTION] Connection was already closed: {conn}")
        except Exception as e:
            print(f"[CLOSE CONNECTION ERROR] Error closing connection: {e}")

    def is_connection_closed(self, conn):
        return conn.closed

    def info(self):
        with self.lock:
            total_connections = self.in_use_conn + len(self.all_connections)
            print(f"[INFO] In use: {self.in_use_conn}, Available: {len(self.all_connections)}, Total: {total_connections}, "
                  f"Threads waiting: {self.threads_waiting}, Total threads: {self.total_threads}")

    def maintain_minconn(self):
        """Ensure there are at least minconn connections in the pool."""
        with self.lock:
            while len(self.all_connections) < self.minconn:
                self.all_connections.append(self.create_new_connection())
            print(f"[MAINTENANCE] Ensured minimum connections. Available: {len(self.all_connections)}")

    def start_cleanup_thread(self):
        """Start a background thread that cleans up the pool periodically."""
        cleanup_thread = threading.Thread(target=self.cleanup_task, daemon=True)
        cleanup_thread.start()

    def cleanup_task(self):
        """Periodically clean up the pool to ensure it's not overpopulated."""
        while True:
            time.sleep(self.cleanup_interval)
            self.cleanup_pool_async()

    def cleanup_pool_async(self):
        """Perform cleanup asynchronously."""
        threading.Thread(target=self.cleanup_pool).start() 

==================== 
FILE: server_package/connect.py 

from connection_pool.server_package.conn_pool import ConnectionPool
from connection_pool.server_package.config import connection_pool_config


class DatabaseConnectionError(Exception):
    pass


params = connection_pool_config()
pool = ConnectionPool(params['minconn'], params['maxconn'], params['cleanup_interval'])


def connect():
    try:
        return pool.acquire()
    except Exception as e:
        print(f"[CONNECT ERROR] Failed to acquire connection: {e}")
        raise DatabaseConnectionError(f"Connect error = {e}")


def release_connection(conn):
    try:
        pool.release(conn)
    except Exception as e:
        print(f"[RELEASE ERROR] Failed to release connection: {e}")
        raise e


def handle_connection_error(conn):
    try:
        pool.handle_connection_error(conn)
    except Exception as e:
        print(f"[HANDLE ERROR] Failed to handle connection error: {e}")
        raise e


def info():
    pool.info()

 

==================== 
FILE: server_package/stress_test.py 

import time
import random
from concurrent.futures import ThreadPoolExecutor
from connection_pool.server_package.connect import connect, release_connection, handle_connection_error, info
from connection_pool.server_package.config import stress_test
from psycopg2 import sql

params = stress_test()
NUM_THREADS = int(params['num_threads'])
TEST_DURATION = int(params['test_duration'])


def stress_test_operation(thread_id):
    start_time = time.time()
    conn = None
    try:
        while time.time() - start_time < TEST_DURATION:
            try:
                conn = connect()
                with conn.cursor() as cur:
                    if random.random() < 0.1:
                        cur.execute("SELECT * FROM non_existing_table")
                        print(f"[SELECT ERROR]")
                    else:
                        operation = random.choice(["insert", "select"])
                        if operation == "insert":
                            query = sql.SQL("INSERT INTO items (item_name, item_quantity) VALUES (%s, %s)")
                            cur.execute(query, (f'Item {random.randint(1, 100000)}', random.randint(1, 100)))
                            print(f"[INSERT]")
                        elif operation == "select":
                            query = sql.SQL("SELECT * FROM items ORDER BY item_id DESC LIMIT 1")
                            cur.execute(query)
                            print(f"[SELECT]")
                            result = cur.fetchone()
                            if result:
                                print(f"Thread {thread_id}: {result}")
                    conn.commit()
                info()
            except Exception as e:
                if conn:
                    handle_connection_error(conn)
                print(f"Thread {thread_id} encountered an error: {e}")
            finally:
                if conn:
                    release_connection(conn)
                    conn = None
            time.sleep(random.uniform(0.01, 0.1))
    except Exception as e:
        print(f"Thread {thread_id} encountered a fatal error: {e}")


def run_stress_test():
    start_time = time.time()
    with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:
        futures = [executor.submit(stress_test_operation, thread_id) for thread_id in range(NUM_THREADS)]
        for future in futures:
            future.result()
    print(f"Stress test completed in {time.time() - start_time} seconds")


if __name__ == "__main__":
    run_stress_test()
    print("End of Stress Test")
 

==================== 
FILE: server_package/test_connection_usage.py 

import time
from concurrent.futures import ThreadPoolExecutor
import threading
from connection_pool.server_package.config import test_connection_usage
from connection_pool.server_package.conn_pool import ConnectionPool

params = test_connection_usage()
MINCON = int(params['minconn'])
MAXCON = int(params['minconn'])
CLEANUP_INTERVAL = int(params['cleanup_interval'])
TEST_DURATION = int(params['test_duration'])
MAX_WORKERS = int(params['max_workers'])
NUM_THREADS = int(params['num_threads'])


def test_connection_usage(pool, duration):
    start_time = time.time()

    def use_connection(pool):
        while time.time() - start_time < duration:
            conn = pool.acquire()
            # Symulacja d³u¿szej operacji, aby po³¹czenie by³o zajête
            time.sleep(0.5)  # 0.1
            pool.release(conn)
            time.sleep(1.0)  #0.05

    def log_status(pool):
        while time.time() - start_time < duration:
            with pool.lock:
                print(
                    f"[STATUS] In use: {pool.in_use_conn}, Available: {len(pool.all_connections)}, Total: {pool.in_use_conn + len(pool.all_connections)}, "
                    f"Threads waiting: {pool.threads_waiting}, Total threads: {pool.total_threads}")
            time.sleep(1)

    # Uruchamiamy w¹tki do wykonywania operacji na po³¹czeniach
    with ThreadPoolExecutor(MAX_WORKERS) as executor:
        futures = [executor.submit(use_connection, pool) for _ in range(NUM_THREADS)]

        # Uruchamiamy dodatkowy w¹tek do logowania statusu puli po³¹czeñ
        log_thread = threading.Thread(target=log_status, args=(pool,))
        log_thread.start()

        for future in futures:
            future.result()

    # Zakoñczenie logowania
    log_thread.join()
    print("Test completed.")


if __name__ == "__main__":
    pool = ConnectionPool(MINCON, MAXCON, CLEANUP_INTERVAL)
    test_connection_usage(pool, TEST_DURATION)
 

==================== 
FILE: server_package/settings.ini 

[postgresql]
host=127.0.0.1
database=CP_BASE
user=pozamiataj
password=pozamiataj.pl

[connection_pool]
minconn=5
maxconn=100
cleanup_interval=29

[server_data]
host=127.0.0.1
port=65432
buffer_size=1024

[stress_test]
num_threads=110
test_duration=480

[test_connection_usage]
minconn=5
maxconn=8
cleanup_interval=30
test_duration=180
max_workers=50
num_threads=200