==================== 
FILE: connection_pool/server_package/config.py 

from configparser import ConfigParser


def load_config(filename='settings.ini', section=None):
    if section is None:
        raise ValueError("Section must be specified")

    parser = ConfigParser()
    parser.read(filename)

    config = {}
    if parser.has_section(section):
        params = parser.items(section)
        for param in params:
            config[param[0]] = param[1]
    else:
        raise Exception(f'Section {section} not found in the {filename} file')

    return config


def db_config(filename='settings.ini', section='postgresql'):
    return load_config(filename, section)


def connection_pool_config(filename='settings.ini', section='connection_pool'):
    return load_config(filename, section)


def server_data(filename='settings.ini', section='server_data'):
    return load_config(filename, section)


def stress_test(filename='settings.ini', section='stress_test'):
    return load_config(filename, section)


==================== 
FILE: connection_pool/server_package/conn_pool.py 

import time
from psycopg2 import connect as pg_connect
from connection_pool.server_package.config import db_config


class ConnectionPool:
    def __init__(self, minconn, maxconn, cleanup_interval):
        self.minconn = int(minconn)
        self.maxconn = int(maxconn)
        self.cleanup_interval = int(cleanup_interval)
        self.all_connections = []
        self.in_use_conn = 0
        self.last_cleanup_time = time.time()
        self.initialize_pool()

    def initialize_pool(self):
        for _ in range(self.minconn):
            self.all_connections.append(self.create_new_connection())
        print(f"Initialized connection pool with {self.minconn} connections.")

    def create_new_connection(self):
        params = db_config()
        return pg_connect(**params)

    def aquire(self):
        self.cleanup_if_needed()
        if self.all_connections:
            conn = self.all_connections.pop()
            self.in_use_conn += 1
            print(f"[AQUIRE] Acquired connection. In use: {self.in_use_conn}, Available: {len(self.all_connections)}")
            return conn
        elif self.in_use_conn < self.maxconn:
            self.in_use_conn += 1
            print(f"[CREATE] Creating new connection. In use: {self.in_use_conn}, Available: {len(self.all_connections)}")
            return self.create_new_connection()
        else:
            raise Exception("[FULL] Max connections limit reached")

    def release(self, conn):
        if self.in_use_conn > 0:
            self.in_use_conn -= 1
            if len(self.all_connections) < self.maxconn:
                if not conn.closed:
                    self.all_connections.append(conn)
                    print(f"[RELEASE] Released connection. In use: {self.in_use_conn}, Available: {len(self.all_connections)}")
                else:
                    print("[RELEASE] Connection was already closed, not adding back to the pool.")
            else:
                print(f"[RELEASE] Pool is full, closing connection.")
                conn.close()
        else:
            print("[RELEASE] No connections in use, something went wrong.")

    def handle_connection_error(self, conn):
        if self.in_use_conn > 0:
            self.in_use_conn -= 1
            conn.close()
            if len(self.all_connections) < self.minconn:
                self.all_connections.append(self.create_new_connection())
            print(f"[ERROR] Handled connection error. In use: {self.in_use_conn}, Available: {len(self.all_connections)}")
        else:
            print("[ERROR] No connections in use, something went wrong.")

    def cleanup_if_needed(self):
        current_time = time.time()
        if current_time - self.last_cleanup_time >= self.cleanup_interval:
            self.cleanup_pool()
            self.last_cleanup_time = current_time

    def cleanup_pool(self):
        while len(self.all_connections) > self.minconn:
            conn = self.all_connections.pop()
            conn.close()
            print("[CLEANUP] Closed an idle connection.")

    def info(self):
        total_connections = self.in_use_conn + len(self.all_connections)
        print(f"[INFO] Number of pool: {self.in_use_conn}, Available connections: {len(self.all_connections)}, Total: {total_connections}")
 

==================== 
FILE: connection_pool/server_package/connect.py 

from connection_pool.server_package.conn_pool import ConnectionPool
from connection_pool.server_package.config import connection_pool_config


class DatabaseConnectionError(Exception):
    pass


params = connection_pool_config()
pool = ConnectionPool(params['minconn'], params['maxconn'], params['cleanup_interval'])
pool.cleanup_if_needed()


def connect():
    try:
        return pool.aquire()
    except (Exception) as e:
        raise DatabaseConnectionError(f"Connect error = {e}")


def release_connection(conn):
    pool.release(conn)


def handle_connection_error(conn):
    pool.handle_connection_error(conn)


def info():
    pool.info()


 

==================== 
FILE: connection_pool/server_package/server.py 

import json
import socket
from connection_pool.server_package.config import server_data


class Server:
    def __init__(self, srv_host, srv_port, srv_buff):
        self.srv_host = srv_host
        self.srv_port = int(srv_port)
        self.srv_buff = int(srv_buff)

    def server_connection(self):

        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.bind((self.srv_host, self.srv_port))
            s.listen()
            print("Server started.")
            while True:
                conn, addr = s.accept()
                with conn:
                    print(f"Connected by {addr}")
                    received_data = conn.recv(self.srv_buff)
                    print(f'Server USER DATA = {received_data}')

    @staticmethod
    def json_decode_received_data(received_data):
        decoded_data = json.loads(received_data)
        if 'login' in decoded_data['command']:
            print(f"Command received from Client: login")
            return decoded_data["command"]
        else:
            print(f"Command received from Client: {decoded_data['command']}")
        return decoded_data["command"]

    @staticmethod
    def json_serialize_response(response):
        return json.dumps(response)


def start():
    params = server_data()
    server = Server(params['host'], params['port'], params['buffer_size'])
    server.server_connection()


if __name__ == '__main__':
    start()
 

==================== 
FILE: connection_pool/server_package/stress_test.py 

import time
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from connection_pool.server_package.connect import connect, release_connection, handle_connection_error, info
from connection_pool.server_package.config import stress_test
from psycopg2 import sql


params = stress_test()
NUM_THREADS = int(params['num_threads'])
TEST_DURATION = int(params['test_duration'])

def stress_test_operation(thread_id):
    start_time = time.time()
    conn = None
    while time.time() - start_time < TEST_DURATION:
        try:
            conn = connect()
            with conn.cursor() as cur:
                if random.random() < 0.1:
                    cur.execute("SELCT * FROM non_existing_table")
                    print(f"[SELCT ERROR]")
                else:
                    operation = random.choice(["insert", "select"])
                    if operation == "insert":
                        query = sql.SQL("INSERT INTO items (item_name, item_quantity) VALUES (%s, %s)")
                        cur.execute(query, (f'Item {random.randint(1, 100000)}', random.randint(1, 100)))
                        print(f"[INSERT]")
                    elif operation == "select":
                        query = sql.SQL("SELECT * FROM items ORDER BY item_id DESC LIMIT 1")
                        print(f"[SELECT]")
                        cur.execute(query)
                        result = cur.fetchone()
                        if result:
                            print(f"Thread {thread_id}: {result}")
                conn.commit()
            info()
        except Exception as e:
            if conn:
                handle_connection_error(conn)
            print(f"Thread {thread_id} encountered an error: {e}")
            conn = None
        finally:
            if conn:
                release_connection(conn)

        time.sleep(random.uniform(0.01, 0.1))

    time.sleep(TEST_DURATION * 0.1)


def run_stress_test():
    start_time = time.time()
    with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:
        futures = [executor.submit(stress_test_operation, thread_id) for thread_id in range(NUM_THREADS)]
        for future in as_completed(futures):
            try:
                future.result()
            except Exception as e:
                print(f"Error occurred: {e}")
    duration = time.time() - start_time
    print(f"Stress test completed in {duration} seconds")


if __name__ == "__main__":
    run_stress_test() 


==================== 
FILE: connection_pool/server_package/settings.ini
[postgresql]
host=127.0.0.1
database=CP_BASE
user=pozamiataj
password=pozamiataj.pl

[connection_pool]
minconn=5
maxconn=100
cleanup_interval=60

[server_data]
host=127.0.0.1
port=65432
buffer_size=1024

[stress_test]
num_threads=110
test_duration=300
